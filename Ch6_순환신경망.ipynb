{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "47OtHpEsDvJ8"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n_hidden = 35\n",
        "lr = 0.01\n",
        "epochs = 1000\n",
        "\n",
        "string = \"hello pytorch. how long can a rnn cell remember?\" # show is your limit!\n",
        "chars = \"abcdefghijklmnopqrstuvwxyz ?!.,:;01\"\n",
        "char_list = [i for i in chars]\n",
        "n_letters = len(char_list)"
      ],
      "metadata": {
        "id": "rPStxUQiD3N8"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def string_to_onehot(string):\n",
        "    start = np.zeros(shape=len(char_list), dtype=int)\n",
        "    end = np.zeros(shape=len(char_list), dtype=int)\n",
        "    start[-2] = 1\n",
        "    end[-2] = 1\n",
        "    for i in string:\n",
        "        idx = char_list.index(i)\n",
        "        zero = np.zeros(shape=n_letters, dtype=int)\n",
        "        zero[idx] = 1\n",
        "        start = np.vstack([start, zero])\n",
        "    output = np.vstack([start, end])\n",
        "    return output"
      ],
      "metadata": {
        "id": "ILISIw5VEUzC"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def onehot_to_word(onehot_1):\n",
        "    onehot = torch.Tensor.numpy(onehot_1)\n",
        "    return char_list[onehot.argmax()]"
      ],
      "metadata": {
        "id": "tl4KvfXFINm3"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class RNN(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        super(RNN, self).__init__()\n",
        "\n",
        "        self.input_size = input_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.output_size = output_size\n",
        "\n",
        "        self.i2h = nn.Linear(input_size, hidden_size)\n",
        "        self.h2h = nn.Linear(hidden_size, hidden_size)\n",
        "        self.i2o = nn.Linear(hidden_size, output_size)\n",
        "        self.act_fn = nn.Tanh()\n",
        "\n",
        "    def forward(self, input, hidden):\n",
        "        hidden = self.act_fn(self.i2h(input)+self.h2h(hidden))\n",
        "        output = self.i2o(hidden)\n",
        "        return output, hidden\n",
        "\n",
        "    def init_hidden(self):\n",
        "        return torch.zeros(1, self.hidden_size)\n",
        "\n",
        "rnn = RNN(n_letters, n_hidden, n_letters)"
      ],
      "metadata": {
        "id": "uqrGLUq_IW8P"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss_func = nn.MSELoss()\n",
        "optimizer = torch.optim.Adam(rnn.parameters(), lr=lr)"
      ],
      "metadata": {
        "id": "uZzARiOwJ6E1"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "one_hot = torch.from_numpy(string_to_onehot(string)).type_as(torch.FloatTensor())\n",
        "\n",
        "for i in range(epochs):\n",
        "    rnn.zero_grad()\n",
        "    total_loss = 0\n",
        "    hidden = rnn.init_hidden()\n",
        "\n",
        "    for j in range(one_hot.size()[0]-1):\n",
        "        input_ = one_hot[j:j+1,:]\n",
        "        target = one_hot[j+1]\n",
        "\n",
        "        output, hidden = rnn.forward(input_, hidden)\n",
        "        loss = loss_func(output.view(-1), target.view(-1))\n",
        "        total_loss += loss\n",
        "        input_ = output\n",
        "\n",
        "    total_loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if i % 10 == 0:\n",
        "        print(total_loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dWJ4IOvPKFmy",
        "outputId": "92e7d886-bd92-4255-9997-8e5e2c77cafb"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(1.9652, grad_fn=<AddBackward0>)\n",
            "tensor(0.8797, grad_fn=<AddBackward0>)\n",
            "tensor(0.5571, grad_fn=<AddBackward0>)\n",
            "tensor(0.3682, grad_fn=<AddBackward0>)\n",
            "tensor(0.2537, grad_fn=<AddBackward0>)\n",
            "tensor(0.1927, grad_fn=<AddBackward0>)\n",
            "tensor(0.1510, grad_fn=<AddBackward0>)\n",
            "tensor(0.1216, grad_fn=<AddBackward0>)\n",
            "tensor(0.1001, grad_fn=<AddBackward0>)\n",
            "tensor(0.0877, grad_fn=<AddBackward0>)\n",
            "tensor(0.0750, grad_fn=<AddBackward0>)\n",
            "tensor(0.0638, grad_fn=<AddBackward0>)\n",
            "tensor(0.0591, grad_fn=<AddBackward0>)\n",
            "tensor(0.0578, grad_fn=<AddBackward0>)\n",
            "tensor(0.0473, grad_fn=<AddBackward0>)\n",
            "tensor(0.0410, grad_fn=<AddBackward0>)\n",
            "tensor(0.0365, grad_fn=<AddBackward0>)\n",
            "tensor(0.0329, grad_fn=<AddBackward0>)\n",
            "tensor(0.0400, grad_fn=<AddBackward0>)\n",
            "tensor(0.0316, grad_fn=<AddBackward0>)\n",
            "tensor(0.0277, grad_fn=<AddBackward0>)\n",
            "tensor(0.0248, grad_fn=<AddBackward0>)\n",
            "tensor(0.0338, grad_fn=<AddBackward0>)\n",
            "tensor(0.0259, grad_fn=<AddBackward0>)\n",
            "tensor(0.0216, grad_fn=<AddBackward0>)\n",
            "tensor(0.0242, grad_fn=<AddBackward0>)\n",
            "tensor(0.0207, grad_fn=<AddBackward0>)\n",
            "tensor(0.0180, grad_fn=<AddBackward0>)\n",
            "tensor(0.0164, grad_fn=<AddBackward0>)\n",
            "tensor(0.0161, grad_fn=<AddBackward0>)\n",
            "tensor(0.0185, grad_fn=<AddBackward0>)\n",
            "tensor(0.0146, grad_fn=<AddBackward0>)\n",
            "tensor(0.0135, grad_fn=<AddBackward0>)\n",
            "tensor(0.0181, grad_fn=<AddBackward0>)\n",
            "tensor(0.0192, grad_fn=<AddBackward0>)\n",
            "tensor(0.0139, grad_fn=<AddBackward0>)\n",
            "tensor(0.0119, grad_fn=<AddBackward0>)\n",
            "tensor(0.0112, grad_fn=<AddBackward0>)\n",
            "tensor(0.0221, grad_fn=<AddBackward0>)\n",
            "tensor(0.0133, grad_fn=<AddBackward0>)\n",
            "tensor(0.0110, grad_fn=<AddBackward0>)\n",
            "tensor(0.0098, grad_fn=<AddBackward0>)\n",
            "tensor(0.0092, grad_fn=<AddBackward0>)\n",
            "tensor(0.0203, grad_fn=<AddBackward0>)\n",
            "tensor(0.0112, grad_fn=<AddBackward0>)\n",
            "tensor(0.0095, grad_fn=<AddBackward0>)\n",
            "tensor(0.0082, grad_fn=<AddBackward0>)\n",
            "tensor(0.0077, grad_fn=<AddBackward0>)\n",
            "tensor(0.0073, grad_fn=<AddBackward0>)\n",
            "tensor(0.0070, grad_fn=<AddBackward0>)\n",
            "tensor(0.0190, grad_fn=<AddBackward0>)\n",
            "tensor(0.0105, grad_fn=<AddBackward0>)\n",
            "tensor(0.0083, grad_fn=<AddBackward0>)\n",
            "tensor(0.0071, grad_fn=<AddBackward0>)\n",
            "tensor(0.0068, grad_fn=<AddBackward0>)\n",
            "tensor(0.0068, grad_fn=<AddBackward0>)\n",
            "tensor(0.0060, grad_fn=<AddBackward0>)\n",
            "tensor(0.0081, grad_fn=<AddBackward0>)\n",
            "tensor(0.0080, grad_fn=<AddBackward0>)\n",
            "tensor(0.0067, grad_fn=<AddBackward0>)\n",
            "tensor(0.0056, grad_fn=<AddBackward0>)\n",
            "tensor(0.0053, grad_fn=<AddBackward0>)\n",
            "tensor(0.0125, grad_fn=<AddBackward0>)\n",
            "tensor(0.0063, grad_fn=<AddBackward0>)\n",
            "tensor(0.0050, grad_fn=<AddBackward0>)\n",
            "tensor(0.0045, grad_fn=<AddBackward0>)\n",
            "tensor(0.0046, grad_fn=<AddBackward0>)\n",
            "tensor(0.0165, grad_fn=<AddBackward0>)\n",
            "tensor(0.0057, grad_fn=<AddBackward0>)\n",
            "tensor(0.0047, grad_fn=<AddBackward0>)\n",
            "tensor(0.0040, grad_fn=<AddBackward0>)\n",
            "tensor(0.0037, grad_fn=<AddBackward0>)\n",
            "tensor(0.0046, grad_fn=<AddBackward0>)\n",
            "tensor(0.0127, grad_fn=<AddBackward0>)\n",
            "tensor(0.0055, grad_fn=<AddBackward0>)\n",
            "tensor(0.0043, grad_fn=<AddBackward0>)\n",
            "tensor(0.0036, grad_fn=<AddBackward0>)\n",
            "tensor(0.0039, grad_fn=<AddBackward0>)\n",
            "tensor(0.0065, grad_fn=<AddBackward0>)\n",
            "tensor(0.0046, grad_fn=<AddBackward0>)\n",
            "tensor(0.0037, grad_fn=<AddBackward0>)\n",
            "tensor(0.0032, grad_fn=<AddBackward0>)\n",
            "tensor(0.0249, grad_fn=<AddBackward0>)\n",
            "tensor(0.0054, grad_fn=<AddBackward0>)\n",
            "tensor(0.0040, grad_fn=<AddBackward0>)\n",
            "tensor(0.0033, grad_fn=<AddBackward0>)\n",
            "tensor(0.0029, grad_fn=<AddBackward0>)\n",
            "tensor(0.0027, grad_fn=<AddBackward0>)\n",
            "tensor(0.0026, grad_fn=<AddBackward0>)\n",
            "tensor(0.0061, grad_fn=<AddBackward0>)\n",
            "tensor(0.0041, grad_fn=<AddBackward0>)\n",
            "tensor(0.0035, grad_fn=<AddBackward0>)\n",
            "tensor(0.0029, grad_fn=<AddBackward0>)\n",
            "tensor(0.0025, grad_fn=<AddBackward0>)\n",
            "tensor(0.0023, grad_fn=<AddBackward0>)\n",
            "tensor(0.0022, grad_fn=<AddBackward0>)\n",
            "tensor(0.0052, grad_fn=<AddBackward0>)\n",
            "tensor(0.0063, grad_fn=<AddBackward0>)\n",
            "tensor(0.0033, grad_fn=<AddBackward0>)\n",
            "tensor(0.0026, grad_fn=<AddBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "start = torch.zeros(1, len(char_list))\n",
        "start[:, -2] = 1\n",
        "\n",
        "with torch.no_grad():\n",
        "    hidden = rnn.init_hidden()\n",
        "    input_ = start\n",
        "    output_string = \"\"\n",
        "    for i in range(len(string)):\n",
        "        output, hidden = rnn.forward(input_, hidden)\n",
        "        output_string += onehot_to_word(output.data)\n",
        "        input_ = output\n",
        "\n",
        "print(output_string)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LLFtAMaNL0nd",
        "outputId": "e9139c60-cd92-4e57-9bfd-ff00a61b38dc"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hello p eorm eonc c ememlt ro poe emalnnw memrtr\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 2000\n",
        "print_every = 100\n",
        "plot_every = 10\n",
        "\n",
        "chunk_len = 200\n",
        "\n",
        "hidden_size = 100\n",
        "batch_size = 1\n",
        "num_layers = 1\n",
        "embedding_size = 70\n",
        "lr = 0.002"
      ],
      "metadata": {
        "id": "qrnyExg1WxWC"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import string\n",
        "\n",
        "all_characters = string.printable\n",
        "n_characters = len(all_characters)\n",
        "print(all_characters)\n",
        "print(\"num_chars =\", n_characters)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xr0JczahMXPv",
        "outputId": "9aa95ac4-a72e-4dca-872f-9c9db54f87b3"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0123456789abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~ \t\n",
            "\r\u000b\f\n",
            "num_chars =  100\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install unidecode"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DYEjlIxYQj5M",
        "outputId": "54c68a9b-f9f5-4a1e-dd88-b28fb0619b56"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting unidecode\n",
            "  Downloading Unidecode-1.3.6-py3-none-any.whl (235 kB)\n",
            "\u001b[K     |████████████████████████████████| 235 kB 15.5 MB/s \n",
            "\u001b[?25hInstalling collected packages: unidecode\n",
            "Successfully installed unidecode-1.3.6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import unidecode\n",
        "\n",
        "file = unidecode.unidecode(open('/content/shakespeare.txt').read())\n",
        "file_len = len(file)\n",
        "print('file_len =', file_len)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hy0gnaQKOuuS",
        "outputId": "4995b774-969f-482d-bb04-c7c280265892"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "file_len = 1115394\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "def random_chunk():\n",
        "    start_index = random.randint(0, file_len - chunk_len)\n",
        "    end_index = start_index + chunk_len + 1\n",
        "    return file[start_index:end_index]"
      ],
      "metadata": {
        "id": "S_jKOTCTQR33"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def char_tensor(string):\n",
        "    tensor = torch.zeros(len(string)).long()\n",
        "    for c in range(len(string)):\n",
        "        tensor[c] = all_characters.index(string[c])\n",
        "    return tensor\n",
        "\n",
        "print(char_tensor('ABCdef'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VDpO2aoyQ41o",
        "outputId": "8ad63b7d-986f-45b9-c147-c6979d34c025"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([36, 37, 38, 13, 14, 15])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def random_training_set():\n",
        "    chunk = random_chunk()\n",
        "    inp = char_tensor(chunk[:-1])\n",
        "    target = char_tensor(chunk[1:])\n",
        "    return inp, target"
      ],
      "metadata": {
        "id": "MJ1hHUABRK7N"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class RNN(nn.Module):\n",
        "    def __init__(self, input_size, embedding_size, hidden_size, output_size, num_layers=1):\n",
        "        super(RNN, self).__init__()\n",
        "        self.input_size = input_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.output_size = output_size\n",
        "        self.num_layers = num_layers\n",
        "        self.embedding_size = embedding_size\n",
        "\n",
        "        self.encoder = nn.Embedding(input_size, embedding_size)\n",
        "        self.rnn = nn.RNN(embedding_size, hidden_size, num_layers)\n",
        "        self.decoder = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "    def forward(self, input, hidden):\n",
        "        out = self.encoder(input.view(1, -1))\n",
        "        out, hidden = self.rnn(out, hidden)\n",
        "        out = self.decoder(out.view(batch_size, -1))\n",
        "        return out, hidden\n",
        "\n",
        "    def init_hidden(self):\n",
        "        hidden = torch.zeros(self.num_layers, batch_size, hidden_size)\n",
        "        return hidden"
      ],
      "metadata": {
        "id": "uBdhpXOFTBgv"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = RNN(input_size=n_characters,\n",
        "            embedding_size=embedding_size,\n",
        "            hidden_size=hidden_size,\n",
        "            output_size=n_characters,\n",
        "            num_layers=2)"
      ],
      "metadata": {
        "id": "EsFrcTNSUC5q"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inp = char_tensor(\"A\")\n",
        "hidden = model.init_hidden()\n",
        "out, hidden = model(inp, hidden)"
      ],
      "metadata": {
        "id": "p2S_55l_WYz4"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "loss_func = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "BgEJauNZY8ce"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test():\n",
        "    start_str = \"b\"\n",
        "    inp = char_tensor(start_str)\n",
        "    hidden = model.init_hidden()\n",
        "    x = inp\n",
        "\n",
        "    print(start_str,end=\"\")\n",
        "    for i in range(200):\n",
        "        output,hidden = model(x,hidden)\n",
        "\n",
        "        output_dist = output.data.view(-1).div(0.8).exp()\n",
        "        top_i = torch.multinomial(output_dist, 1)[0]\n",
        "        predicted_char = all_characters[top_i]\n",
        "\n",
        "        print(predicted_char,end=\"\")\n",
        "\n",
        "        x = char_tensor(predicted_char)"
      ],
      "metadata": {
        "id": "7bxIzYzDY4x2"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(num_epochs):\n",
        "    total = char_tensor(random_chunk())\n",
        "    inp = total[:-1]\n",
        "    label = total[1:]\n",
        "    hidden = model.init_hidden()\n",
        "\n",
        "    loss = torch.tensor([0]).type(torch.FloatTensor)\n",
        "    optimizer.zero_grad()\n",
        "    for j in range(chunk_len-1):\n",
        "        x = inp[j]\n",
        "        y_ = label[j].unsqueeze(0).type(torch.LongTensor)\n",
        "        y, hidden = model(x, hidden)\n",
        "        loss += loss_func(y, y_)\n",
        "\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if i % 100 == 0:\n",
        "        print(\"\\n\",loss/chunk_len,\"\\n\")\n",
        "        test()\n",
        "        print(\"\\n\",\"=\"*100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yOhGv4bHW5JA",
        "outputId": "0258b5e4-858a-4ab2-885f-3c5443f90f81"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " tensor([4.6213], grad_fn=<DivBackward0>) \n",
            "\n",
            "(0_@xJUsLf\n",
            " ====================================================================================================\n",
            "\n",
            " tensor([2.3143], grad_fn=<DivBackward0>) \n",
            "\n",
            "bnd tour for lalve shite the tou thef s bacare theth y mnbnbe do ties kagotos. lithe  oind win iy shin rere Knir .ay int th tuperes lili th theraty hall Jide our the'd thr Io has at thanitC.\n",
            "\n",
            "nor b't.\n",
            "\n",
            " ====================================================================================================\n",
            "\n",
            " tensor([2.2534], grad_fn=<DivBackward0>) \n",
            "\n",
            "bod this wisteabe hat the, ilg and belerr hage agonk, younn, beriorce, and then stanly t'oed chall thou deith warce the orghall me mest and four.\n",
            "\n",
            "CICEDIBAENG:\n",
            "Thy wil\n",
            "EYEN.:\n",
            "Wour on thand thea wore th\n",
            " ====================================================================================================\n",
            "\n",
            " tensor([2.1245], grad_fn=<DivBackward0>) \n",
            "\n",
            "buth in my bet will thun, :upecrs not mith rof male than woved\n",
            "The brust the be wond wreruse whe in inny\n",
            "Se the hien lour in in me ciase thy me of moree, and to wist to bean the ins oul sour wear sest,\n",
            " ====================================================================================================\n",
            "\n",
            " tensor([1.9960], grad_fn=<DivBackward0>) \n",
            "\n",
            "brow the thert.\n",
            "\n",
            "PEN.\n",
            "TUI Hot Bome seoss copit the diy wore ky pake to naFt, is of eost Poth sie thean thee,\n",
            "Ant I shon yout the is his my so praee vulldo,\n",
            "EV I sher\n",
            "And here seaver to papet now sfall \n",
            " ====================================================================================================\n",
            "\n",
            " tensor([1.8816], grad_fn=<DivBackward0>) \n",
            "\n",
            "blemas ret-your hat woult grous regind dece mancying to by breet countere seem-al of till ar rot ell us brow;\n",
            "And the of one and his in the our herour nhach ot the I saved, hik hes-\n",
            "\n",
            "CBUCSTARINCOLHERA:\n",
            " ====================================================================================================\n",
            "\n",
            " tensor([2.1179], grad_fn=<DivBackward0>) \n",
            "\n",
            "by the the die,\n",
            "Nother the frems, you of so to hancing coughek soalinow\n",
            "\n",
            "RELAUD:\n",
            "And bese you me treart' thy shere?\n",
            "\n",
            "SARTIO:\n",
            "I bear all wall geaks at ane buse all and mids godle shat for it Vurvor, you\n",
            " ====================================================================================================\n",
            "\n",
            " tensor([1.8449], grad_fn=<DivBackward0>) \n",
            "\n",
            "brost, and nold whonournnson the kiscontime; bropemel, chard thou sus yould whot and grome on thou the pegpintor, hart as your is sut he blord of the the the solly piorthem, whonk rid es of wall thas b\n",
            " ====================================================================================================\n",
            "\n",
            " tensor([2.1188], grad_fn=<DivBackward0>) \n",
            "\n",
            "ble, the preat blame he the mide un this colding as fire the, mate the\n",
            "The could ba, and lademan, and thy forth; and the shas the call woummone of Ap fore a plesh, all doos, so cone, the himpter.\n",
            "\n",
            "IUN:\n",
            " ====================================================================================================\n",
            "\n",
            " tensor([2.1839], grad_fn=<DivBackward0>) \n",
            "\n",
            "befter,\n",
            "You graite\n",
            "Lord sere I and a, thit the senest, I ceoth stald\n",
            "Silf not I gave we bake relase for my to mays maro, what the world to perent, you now you leten me led of at is main the stanis, wit\n",
            " ====================================================================================================\n",
            "\n",
            " tensor([1.8236], grad_fn=<DivBackward0>) \n",
            "\n",
            "by!\n",
            "\n",
            "GLODNET:\n",
            "Go, I daye thee.\n",
            "Boter for that Anelasst 'mons thou nor she shall mefore, whom you, so spied; Om woff anso he him'd demour ort sture sill sown a parting ray the be and deave\n",
            "\n",
            "LaRINIS:\n",
            "A d\n",
            " ====================================================================================================\n",
            "\n",
            " tensor([1.9648], grad_fn=<DivBackward0>) \n",
            "\n",
            "brothink look that'd hath them deseath the e'ploth fol with of be taison in this to for then mure is prike so sovest koth that hord, both I lord,\n",
            "The strand love the oke mine brovanast, is then hir the\n",
            " ====================================================================================================\n",
            "\n",
            " tensor([2.0077], grad_fn=<DivBackward0>) \n",
            "\n",
            "be the hatter no saich one and all to ment senfice perby of a wall, and with to my bets me seldog is had him, is Her\n",
            "What 'kis Seop\n",
            "The poortices to dly nerarfemon mondem.\n",
            "\n",
            "LUCIUS:\n",
            "It the can.\n",
            "Wafe: to\n",
            " ====================================================================================================\n",
            "\n",
            " tensor([1.8775], grad_fn=<DivBackward0>) \n",
            "\n",
            "blood not,\n",
            "Wheth as the caster to thought my\n",
            "Whicken, as angirsed there that leen withie her the bounder forch iddost nowel, stand, wiing who trieg and well Slons the batrepittes.\n",
            "\n",
            "LARII:\n",
            "I mardion.\n",
            "\n",
            "G\n",
            " ====================================================================================================\n",
            "\n",
            " tensor([1.6772], grad_fn=<DivBackward0>) \n",
            "\n",
            "by come ontery fay need to:\n",
            "Now Sould.\n",
            "\n",
            "HARUTES:\n",
            "Thy stand him sight of them the shume me swue tay that up this my lord will G the jords your strove him his prayese cate ow him in theaved, detter shall\n",
            " ====================================================================================================\n",
            "\n",
            " tensor([2.0054], grad_fn=<DivBackward0>) \n",
            "\n",
            "be the liest of this, dean unlest thougher, in thee live world\n",
            "When stand the velick we greats deet weith basty since as draed urliet'st leave thou words but veees and Gigh the bear, and my, I'seath, a\n",
            " ====================================================================================================\n",
            "\n",
            " tensor([1.9374], grad_fn=<DivBackward0>) \n",
            "\n",
            "bood thy, die.\n",
            "\n",
            "DUCTIOL:\n",
            "I sest actery to there and dind: O Rarcclast of is a magition: this hithee.\n",
            "\n",
            "DUKENLA:\n",
            "I desble this.\n",
            "\n",
            "MARCIUS:\n",
            "Go, I wands a ern tyey my tron thou spere themer men yelly. I he \n",
            " ====================================================================================================\n",
            "\n",
            " tensor([1.9292], grad_fn=<DivBackward0>) \n",
            "\n",
            "by bord in wortandy to to me with a do at so lied, but him bost and made a warry moring deidons and my loud to it him the his come.\n",
            "Comence to is I are cheacey heart fell strient alis fell at here a sh\n",
            " ====================================================================================================\n",
            "\n",
            " tensor([1.6375], grad_fn=<DivBackward0>) \n",
            "\n",
            "bince of the such the town:\n",
            "Thar me therein if of their worthouk;\n",
            "And see or the percunty. Bothive thould Herind and of they for great upon the withick it the will trunot to a slear, I dellraid's me\n",
            "To\n",
            " ====================================================================================================\n",
            "\n",
            " tensor([1.6014], grad_fn=<DivBackward0>) \n",
            "\n",
            "browd in thee greempece,\n",
            "Sine for mon the king of you wast be were they rounces, and should To to my to brothore fispey, for my cournies the stain shall for see undeit, for it the dowefing\n",
            "That I caut \n",
            " ====================================================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# GRU로 바꾸고 싶다면, 클래스 내에 \n",
        "# self.rnn = nn.RNN(embedding_size, hidden_size, num_layers)를 self.rnn = nn.GRU(embedding_size, hidden_size, num_layers)로 바꾸면 된다."
      ],
      "metadata": {
        "id": "Emd1KQP7XdDq"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# LSTM의 경우에는 클래스를 이렇게 바꾸면 된다\n",
        "class RNN(nn.Module):\n",
        "    def __init__(self, input_size, embedding_size, hidden_size, output_size, num_layers=1):\n",
        "        super(RNN, self).__init__()\n",
        "        self.input_size = input_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.output_size = output_size\n",
        "        self.num_layers = num_layers\n",
        "        self.embedding_size = embedding_size\n",
        "\n",
        "        self.encoder = nn.Embedding(input_size, embedding_size)\n",
        "        self.rnn = nn.LSTM(embedding_size, hidden_size, num_layers)\n",
        "        self.decoder = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "    def forward(self, input, hidden):\n",
        "        out = self.encoder(input.view(batch_size, -1))\n",
        "        out, (hidden, cell) = self.rnn(out, (hidden, cell))\n",
        "        out = self.decoder(out.view(batch_size, -1))\n",
        "        return out, hidden, cell\n",
        "\n",
        "    def init_hidden(self):\n",
        "        hidden = torch.zeros(num_layers, batch_size, hidden_size)\n",
        "        cell = torch.zeros(num_layers, batch_size, hidden_size)\n",
        "        return hidden, cell"
      ],
      "metadata": {
        "id": "aSkTjUCKYUtk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}